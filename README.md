# vision_transformer

=== 1. encoder === 

1) positional encoding 

2) Multi - Head attention (self attention) 

3) point wise feed forward network 

=== 2. decoder === 

4) positional encoding 

5) Masked multi - Head attention (self attention) 

6) multi - Head attention => inference

7) point wise feed forward network 

8) linear - softmax - output 
